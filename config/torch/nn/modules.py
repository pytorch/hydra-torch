# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved
#
# Generated by configen, do not edit.
# See https://github.com/facebookresearch/hydra/tree/master/tools/configen
# fmt: off
# isort:skip_file
# flake8: noqa

from dataclasses import dataclass, field
from omegaconf import MISSING
from typing import Any


@dataclass
class IdentityConf:
    _target_: str = "torch.nn.modules.Identity"
    args: Any = MISSING
    kwargs: Any = MISSING


@dataclass
class LinearConf:
    _target_: str = "torch.nn.modules.Linear"
    in_features: int = MISSING
    out_features: int = MISSING
    bias: bool = True


@dataclass
class BilinearConf:
    _target_: str = "torch.nn.modules.Bilinear"
    in1_features: int = MISSING
    in2_features: int = MISSING
    out_features: int = MISSING
    bias: bool = True


@dataclass
class Conv1dConf:
    _target_: str = "torch.nn.modules.Conv1d"
    in_channels: int = MISSING
    out_channels: int = MISSING
    kernel_size: Any = MISSING  # Union[int, Tuple[int]]
    stride: Any = MISSING  # Union[int, Tuple[int]]
    padding: Any = MISSING  # Union[int, Tuple[int]]
    dilation: Any = MISSING  # Union[int, Tuple[int]]
    groups: int = 1
    bias: bool = True
    padding_mode: str = "zeros"


@dataclass
class Conv2dConf:
    _target_: str = "torch.nn.modules.Conv2d"
    in_channels: int = MISSING
    out_channels: int = MISSING
    kernel_size: Any = MISSING  # Union[int, Tuple[int, int]]
    stride: Any = MISSING  # Union[int, Tuple[int, int]]
    padding: Any = MISSING  # Union[int, Tuple[int, int]]
    dilation: Any = MISSING  # Union[int, Tuple[int, int]]
    groups: int = 1
    bias: bool = True
    padding_mode: str = "zeros"


@dataclass
class Conv3dConf:
    _target_: str = "torch.nn.modules.Conv3d"
    in_channels: int = MISSING
    out_channels: int = MISSING
    kernel_size: Any = MISSING  # Union[int, Tuple[int, int, int]]
    stride: Any = MISSING  # Union[int, Tuple[int, int, int]]
    padding: Any = MISSING  # Union[int, Tuple[int, int, int]]
    dilation: Any = MISSING  # Union[int, Tuple[int, int, int]]
    groups: int = 1
    bias: bool = True
    padding_mode: str = "zeros"


@dataclass
class ConvTranspose1dConf:
    _target_: str = "torch.nn.modules.ConvTranspose1d"
    in_channels: int = MISSING
    out_channels: int = MISSING
    kernel_size: Any = MISSING  # Union[int, Tuple[int]]
    stride: Any = MISSING  # Union[int, Tuple[int]]
    padding: Any = MISSING  # Union[int, Tuple[int]]
    output_padding: Any = MISSING  # Union[int, Tuple[int]]
    groups: int = 1
    bias: bool = True
    dilation: Any = MISSING  # Union[int, Tuple[int]]
    padding_mode: str = "zeros"


@dataclass
class ConvTranspose2dConf:
    _target_: str = "torch.nn.modules.ConvTranspose2d"
    in_channels: int = MISSING
    out_channels: int = MISSING
    kernel_size: Any = MISSING  # Union[int, Tuple[int, int]]
    stride: Any = MISSING  # Union[int, Tuple[int, int]]
    padding: Any = MISSING  # Union[int, Tuple[int, int]]
    output_padding: Any = MISSING  # Union[int, Tuple[int, int]]
    groups: int = 1
    bias: bool = True
    dilation: int = 1
    padding_mode: str = "zeros"


@dataclass
class ConvTranspose3dConf:
    _target_: str = "torch.nn.modules.ConvTranspose3d"
    in_channels: int = MISSING
    out_channels: int = MISSING
    kernel_size: Any = MISSING  # Union[int, Tuple[int, int, int]]
    stride: Any = MISSING  # Union[int, Tuple[int, int, int]]
    padding: Any = MISSING  # Union[int, Tuple[int, int, int]]
    output_padding: Any = MISSING  # Union[int, Tuple[int, int, int]]
    groups: int = 1
    bias: bool = True
    dilation: Any = MISSING  # Union[int, Tuple[int, int, int]]
    padding_mode: str = "zeros"


@dataclass
class DropoutConf:
    _target_: str = "torch.nn.modules.Dropout"
    p: float = 0.5
    inplace: bool = False


@dataclass
class Dropout2dConf:
    _target_: str = "torch.nn.modules.Dropout2d"
    p: float = 0.5
    inplace: bool = False


@dataclass
class Dropout3dConf:
    _target_: str = "torch.nn.modules.Dropout3d"
    p: float = 0.5
    inplace: bool = False


@dataclass
class AlphaDropoutConf:
    _target_: str = "torch.nn.modules.AlphaDropout"
    p: float = 0.5
    inplace: bool = False


@dataclass
class FeatureAlphaDropoutConf:
    _target_: str = "torch.nn.modules.FeatureAlphaDropout"
    p: float = 0.5
    inplace: bool = False
